{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.mx.trainer import Trainer\n",
    "from gluonts.mx.model.deepar import DeepAREstimator\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.model.seasonal_naive import SeasonalNaivePredictor\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from sagemaker.sklearn.processing import ScriptProcessor\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from pathlib import Path\n",
    "# Set the container URI for the MXNet container\n",
    "from sagemaker.mxnet.estimator import MXNet\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env AWS_PROFILE = weather-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Ransaka/Sagemaker-Local-Mode-Example/blob/master/preprocess/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_data_version(bucket: str):\n",
    "    s3 = boto3.client('s3')\n",
    "    objects = s3.list_objects_v2(Bucket=bucket)['Contents']\n",
    "    objects.sort(key=lambda obj: obj['LastModified'], reverse=True)\n",
    "    most_recent_file_key = objects[0]['Key']\n",
    "    return most_recent_file_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "pipeline_session = PipelineSession()\n",
    "role = \"arn:aws:iam::371410071971:role/service-role/AmazonSageMaker-ExecutionRole-20200731T092838\"\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "model_package_group_name = f\"WeatherForecastModelPackageGroupName\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current aws user\n",
    "sts = boto3.client(\"sts\")\n",
    "current_user = sts.get_caller_identity()[\"Arn\"].split(\"/\")[-1]\n",
    "print(current_user)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_bucket = \"clean-city-weather-data-1\"\n",
    "most_recent_file_key = get_most_recent_data_version(bucket=\"clean-city-weather-data-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = Path.cwd() / \"data\" / \"weather.csv\"\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(input_data_bucket).download_file(\n",
    "    most_recent_file_key, local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/recent-weather\"\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", \n",
    "                                default_value=\"ml.m5.xlarge\"\n",
    "                                )\n",
    "model_approval_status = ParameterString(\n",
    "                                name=\"ModelApprovalStatus\", \n",
    "                                default_value=\"PendingManualApproval\"\n",
    "                                )\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterString(name='InputData', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://sagemaker-us-west-2-371410071971/recent-weather/weather.csv')"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "\n",
    "base_dir = \"/opt/ml/processing\"  \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    target_col = os.environ.get('target_col')\n",
    "    id_col = os.environ.get('id_col')\n",
    "    time_col = os.environ.get('time_col')\n",
    "    frequency = os.environ.get('frequency')\n",
    "    forecasting_horizon = int(os.environ.get('forecasting_horizon'))\n",
    "\n",
    "    weather_df = pd.read_csv(f\"{base_dir}/input/weather.csv\",parse_dates=True)\n",
    "    weather_df = weather_df.sort_values(by=[id_col,time_col]).reset_index(drop=True)\n",
    "    weather_df[time_col] = pd.to_datetime(weather_df[time_col])\n",
    "    weather_df = weather_df.set_index(time_col)\n",
    "    \n",
    "    # benchmark our forecast against a baseline\n",
    "    backtest_split_point = weather_df.index[-1] - pd.Timedelta(hours=forecasting_horizon)\n",
    "    backtest_train_df = weather_df[weather_df.index <= backtest_split_point]\n",
    "    backtest_train_df = backtest_train_df.reset_index()\n",
    "    backtest_train_df = backtest_train_df.rename({\"index\": time_col})\n",
    "    backtest_validation_df = weather_df.copy()\n",
    "    backtest_validation_df = backtest_validation_df.reset_index()\n",
    "    backtest_validation_df = backtest_validation_df.rename({\"index\": time_col})\n",
    "    \n",
    "    # write backtest data to s3\n",
    "    backtest_train_df.to_csv(f\"{base_dir}/train/train.csv\", index=False)\n",
    "    backtest_validation_df.to_csv(f\"{base_dir}/validation/validation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-weather-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    env={\"target_col\": \"temp_farenheit\",\n",
    "         \"id_col\": \"ts_id\",\n",
    "            \"time_col\": \"time\",\n",
    "            \"frequency\": \"H\",\n",
    "            \"forecasting_horizon\": \"72\"\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT1H\")\n",
    "step_process = ProcessingStep(name=\"WeatherProcess\", \n",
    "                              processor=sklearn_processor,\n",
    "                              inputs=[\n",
    "                ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "            ],\n",
    "            outputs=[\n",
    "                ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "                ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "            ],\n",
    "    code=\"code/preprocessing.py\",\n",
    "    cache_config=cache_config\n",
    "                              )\n",
    "# this will create a directory in S3 like this: \n",
    "# s3://sagemaker-us-west-2-371410071971/WeatherPipeline-Local-1/0520x0r4fs5b/WeatherProcess/output/train/train.csv\n",
    "# s3://sagemaker-us-west-2-371410071971/WeatherPipeline-Local-1/0520x0r4fs5b/WeatherProcess/output/validation/validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OutputDataConfig.S3OutputPath\n",
    "# s3://sagemaker-us-west-2-371410071971/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/train.py\n",
    "\n",
    "from typing import List\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.mx.model.deepar import DeepAREstimator\n",
    "from gluonts.model.seasonal_naive import SeasonalNaivePredictor\n",
    "from gluonts.mx.trainer import Trainer\n",
    "\n",
    "def df_to_list_dataset(df: pd.DataFrame, id_col: str, target_col: str) -> List[dict]:\n",
    "    # raise an exception if there is no index or the index is not datetime\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Dataframe must have a DatetimeIndex\")\n",
    "    list_dataset = list()\n",
    "    for tsid in df[id_col].unique():\n",
    "        tmp_df = df[df[id_col] == tsid]\n",
    "        ts_dict = {\n",
    "            \"start\": tmp_df.index[0], \"target\": tmp_df[target_col].values, \"item_id\": tsid}\n",
    "        list_dataset.append(ts_dict)\n",
    "    return list_dataset\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # input\n",
    "    parser.add_argument('--target-col', type=str, default=os.environ.get('SM_HP_TARGET_COL'))\n",
    "    parser.add_argument('--id-col', type=str, default=os.environ.get('SM_HP_ID_COL'))\n",
    "    parser.add_argument('--time-col', type=str, default=os.environ.get('SM_HP_TIME_COL'))\n",
    "    parser.add_argument('--frequency', type=str, default=os.environ.get('SM_HP_FREQUENCY'))\n",
    "    parser.add_argument('--forecasting-horizon', type=int, default=os.environ.get('SM_HP_FORECASTING_HORIZON'))\n",
    "    parser.add_argument('--train-dir', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--train-file', type=str, default='train.csv')\n",
    "    # output\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR')) # /opt/ml/model - this is where you save the models\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    target_col = args.target_col\n",
    "    id_col = args.id_col\n",
    "    time_col = args.time_col\n",
    "    frequency = args.frequency\n",
    "    forecasting_horizon = args.forecasting_horizon\n",
    "    # join the args.train_dir and args.train_file with pathlib\n",
    "    train_df = pd.read_csv(Path(args.train_dir, args.train_file), parse_dates=True)     \n",
    "    train_df = train_df.sort_values(\n",
    "        by=[id_col, time_col]).reset_index(drop=True)\n",
    "    train_df[time_col] = pd.to_datetime(train_df[time_col])\n",
    "    train_df = train_df.set_index(time_col)\n",
    "\n",
    "    train_lst = df_to_list_dataset(train_df, id_col, target_col)\n",
    "    train_lds = ListDataset(train_lst, freq=frequency)\n",
    "    # fit the model\n",
    "    deep_ar_estimator = DeepAREstimator(\n",
    "        freq=frequency,\n",
    "        prediction_length=forecasting_horizon,\n",
    "        context_length=forecasting_horizon,\n",
    "        trainer=Trainer(epochs=1,\n",
    "                        learning_rate=1e-3\n",
    "                        )\n",
    "        \n",
    "    )\n",
    "    # fit the benchmark model\n",
    "    snaive_predictor = SeasonalNaivePredictor(freq=frequency,\n",
    "                                            prediction_length=forecasting_horizon\n",
    "                                            )\n",
    "    deep_ar_predictor = deep_ar_estimator.train(train_lds)    \n",
    "    Path(args.model_dir, \"deep_ar_model\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(args.model_dir, \"snaive_model\").mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(deep_ar_predictor, Path(args.model_dir, \"deep_ar_model\" ,\"deep_ar_model.pkl\"))\n",
    "    joblib.dump(snaive_predictor, Path(args.model_dir, \"snaive_model\" ,\"snaive_model.pkl\"))\n",
    "    print(\"model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/requirements.txt\n",
    "\n",
    "gluonts==0.11.9\n",
    "pandas==1.1.5\n",
    "joblib==1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3://sagemaker-us-west-2-371410071971/WeatherPipeline-Local-90/vnp5is5hlp22/WeatherProcess/output/train\n",
    "# https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/using_mxnet.html#create-an-estimator\n",
    "mxnet_estimator = MXNet(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters={\"target_col\": \"temp_farenheit\",\n",
    "         \"id_col\": \"ts_id\",\n",
    "            \"time_col\": \"time\",\n",
    "            \"frequency\": \"H\",\n",
    "            \"forecasting_horizon\": 72\n",
    "         },\n",
    ")\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"WeatherTrain\",\n",
    "    estimator=mxnet_estimator, # training algo + compute resources\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),        \n",
    "    },\n",
    "    cache_config=cache_config,\n",
    "    depends_on=[step_process],\n",
    ")\n",
    "\n",
    "# model artifiact gets sent to: s3://sagemaker-us-west-2-371410071971/pipelines-r7ur1p9auifq-WeatherTrain-xIYAziWhaD/output/model.tar.gz\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluation.py\n",
    "\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# use subprocess to pip install dependencies\n",
    "dependencies = [\"gluonts==0.11.9\", \"pandas==1.1.5\", \"joblib==1.1.1\"]\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *dependencies])\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "\n",
    "\n",
    "\n",
    "def df_to_list_dataset(df: pd.DataFrame, id_col: str, target_col: str) -> List[dict]:\n",
    "    # raise an exception if there is no index or the index is not datetime\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Dataframe must have a DatetimeIndex\")\n",
    "    list_dataset = list()\n",
    "    for tsid in df[id_col].unique():\n",
    "        tmp_df = df[df[id_col] == tsid]\n",
    "        ts_dict = {\n",
    "            \"start\": tmp_df.index[0], \"target\": tmp_df[target_col].values, \"item_id\": tsid}\n",
    "        list_dataset.append(ts_dict)\n",
    "    return list_dataset\n",
    "\n",
    "def create_metrics_df(tgt_metrics=[\"MASE\", \"sMAPE\", \"RMSE\"], **kwargs) -> pd.DataFrame:\n",
    "    df_metrics = pd.DataFrame()\n",
    "    for model_name, metrics_dict in kwargs.items():\n",
    "        df_metrics = pd.DataFrame.join(df_metrics, pd.DataFrame.from_dict(metrics_dict, orient=\"index\", columns=[model_name]), how=\"outer\")\n",
    "    df_metrics = df_metrics.round(2)\n",
    "    df_metrics = df_metrics.reset_index()\n",
    "    df_metrics = df_metrics.rename(columns={\"index\": \"metric\"})\n",
    "    df_metrics = df_metrics[df_metrics[\"metric\"].isin(tgt_metrics)]    \n",
    "    return df_metrics     \n",
    "\n",
    "def create_actuals_vs_forecast_df(forecasts: List[SampleForecast], tss: List[pd.DataFrame], backtest_split_point: pd.Timestamp, model: str) -> pd.DataFrame:\n",
    "    # TO DO: REFACTOR THIS FUNCTION\n",
    "    backtest_fcast_vs_actuals_df = pd.DataFrame()\n",
    "    for forecast, ts_df in zip(forecasts, tss):    \n",
    "        ts_df.index = ts_df.index.to_timestamp()\n",
    "        ts_df = ts_df[ts_df.index > backtest_split_point]\n",
    "        ts_df.columns = ['actual']\n",
    "        ts_df['p50'] = forecast.quantile(0.5)\n",
    "        ts_df['p90'] = forecast.quantile(0.9)\n",
    "        ts_df['p10'] = forecast.quantile(0.1)\n",
    "        ts_df['in_interval'] = np.where((ts_df['actual'] >= ts_df['p10']) &\n",
    "                                            (ts_df['actual'] <= ts_df['p90']), 1, 0)\n",
    "        ts_df['item_id'] = forecast.item_id    \n",
    "        ts_df['model'] = model\n",
    "        backtest_fcast_vs_actuals_df = pd.concat([backtest_fcast_vs_actuals_df, ts_df])\n",
    "    return backtest_fcast_vs_actuals_df    \n",
    "\n",
    "\n",
    "# helpful input keys and values from eviroment variables\n",
    "# ProcessingInputs.0.S3Input.LocalPath = /opt/ml/model\n",
    "# ProcessingInputs.3.S3Input.S3Uri = s3://sagemaker-us-west-2-371410071971/WeatherPipeline-Local-666/code/69552bf494f141614c19e00214edad63/evaluation.py\n",
    "# ProcessingOutputConfig.Outputs.0.S3Output.LocalPath = /opt/ml/evaluation\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # get the location of the model\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model-dir', type=str, default=\"/opt/ml/processing/model\")\n",
    "    # get the location of the validation data\n",
    "    parser.add_argument('--validation-dir', type=str, default=\"/opt/ml/processing/validation\")\n",
    "    parser.add_argument('--validation-file', type=str, default='validation.csv')\n",
    "    # get the location of the test data    \n",
    "    parser.add_argument('--output_dir', type=str, default=\"/opt/ml/processing/evaluation\")\n",
    "\n",
    "    target_col = os.environ.get('target_col')\n",
    "    id_col = os.environ.get('id_col')\n",
    "    time_col = os.environ.get('time_col')\n",
    "    frequency = os.environ.get('frequency')\n",
    "    forecasting_horizon = int(os.environ.get('forecasting_horizon'))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    model_dir = args.model_dir\n",
    "    validation_dir = args.validation_dir\n",
    "    validation_file = args.validation_file\n",
    "    # print(f\"SAGEMAKER ENVIRONMENT VARIABLES: {os.environ}\")\n",
    "    # \n",
    "    # print the directory structure of the operating system\n",
    "    # print(f\"Directory structure of the operating system: {os.listdir()}\")\n",
    "\n",
    "    # of the opt directory\n",
    "\n",
    "    # for root, dirs, files in os.walk(\"/opt\"):\n",
    "    #     for name in files:\n",
    "    #         print(os.path.join(root, name))\n",
    "    #     for name in dirs:\n",
    "    #         print(os.path.join(root, name))\n",
    "\n",
    "    # unzip the directory containing the models\n",
    "    with tarfile.open(Path(model_dir) / \"model.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(path=Path(model_dir))\n",
    "        \n",
    "    deep_ar_predictor = joblib.load(Path(model_dir) / \"deep_ar_model\" / \"deep_ar_model.pkl\")\n",
    "    snaive_predictor = joblib.load(Path(model_dir) / \"snaive_model\" / \"snaive_model.pkl\")\n",
    "\n",
    "    # load the data\n",
    "    validation_df = pd.read_csv(Path(validation_dir, validation_file), parse_dates=True)\n",
    "    validation_df = validation_df.set_index(\"time\")\n",
    "    eval_split_point = validation_df.index[-1] - pd.Timedelta(hours=forecasting_horizon)\n",
    "    eval_validate_lst = df_to_list_dataset(validation_df, id_col, target_col)\n",
    "    eval_validate_lds = ListDataset(eval_validate_lst, freq=frequency)\n",
    "\n",
    "    \n",
    "    deep_ar_forecast_it, deep_ar_tss_it = make_evaluation_predictions(\n",
    "    dataset=eval_validate_lst,  # test dataset\n",
    "    predictor=deep_ar_predictor,  # predictor\n",
    "    num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "    snaive_forecast_it, snaive_tss_it = make_evaluation_predictions(\n",
    "        dataset=eval_validate_lst,  # test dataset\n",
    "        predictor=snaive_predictor,  # predictor\n",
    "        )\n",
    "\n",
    "    # now we can convert these generators to lists\n",
    "    deep_ar_forecasts = list(deep_ar_forecast_it)\n",
    "    deep_ar_tss = list(deep_ar_tss_it)\n",
    "    snaive_forecasts = list(snaive_forecast_it)\n",
    "    snaive_tss = list(snaive_tss_it)\n",
    "\n",
    "    evaluator = Evaluator(quantiles=[0.5])\n",
    "    num_series = validation_df[id_col].unique().shape[0]\n",
    "\n",
    "    deep_ar_agg_metrics, deep_ar_item_metrics = evaluator(deep_ar_tss, \n",
    "                                                      deep_ar_forecasts, \n",
    "                                                      num_series=num_series)\n",
    "\n",
    "    snaive_agg_metrics, snaive_item_metrics = evaluator(snaive_tss, \n",
    "                                                        snaive_forecasts, \n",
    "                                                        num_series=num_series\n",
    "                                                    )\n",
    "\n",
    "    df_metrics = create_metrics_df(deep_ar=deep_ar_agg_metrics, snaive=snaive_agg_metrics)\n",
    "    df_metrics['backtest_window_start'] = (eval_split_point + pd.Timedelta(hours=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    df_metrics['backtest_window_end'] = validation_df.index[-1]\n",
    "    df_metrics['run_dt'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # now make the backtest\n",
    "    df_backtest_deep_ar = create_actuals_vs_forecast_df(deep_ar_forecasts, deep_ar_tss, eval_split_point, 'deep_ar')\n",
    "    df_backtest_snaive = create_actuals_vs_forecast_df(snaive_forecasts, snaive_tss, eval_split_point, 'snaive')\n",
    "    df_backtest = pd.concat([df_backtest_deep_ar, df_backtest_snaive]).reset_index().rename(columns={'index':'time'})\n",
    "\n",
    "    # save the metrics\n",
    "    \n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    df_metrics.to_csv(Path(args.output_dir, 'metrics.csv'), index=False)\n",
    "    df_backtest.to_csv(Path(args.output_dir, 'backtest.csv'), index=False)\n",
    "    #\n",
    "    print(\"Finished Evaluation\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MLeBo1/Desktop/GitHub/aws-weather-pipeline/weather-pipeline/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:270: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# here is where you go to see the images - note the region\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ecr-us-west-2.html\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker import image_uris\n",
    "\n",
    "# get mxnet image\n",
    "mxnet_img_uri = image_uris.retrieve(framework='mxnet',\n",
    "                                    region='us-west-2',\n",
    "                                    version='1.4.1',\n",
    "                                    py_version='py3',\n",
    "                                    image_scope='inference', \n",
    "                                    instance_type=\"ml.m5.xlarge\")\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    command=[\"python3\"],\n",
    "    base_job_name=\"script-weather-eval\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    image_uri=mxnet_img_uri,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    env={\"target_col\": \"temp_farenheit\",\n",
    "         \"id_col\": \"ts_id\",\n",
    "            \"time_col\": \"time\",\n",
    "            \"frequency\": \"H\",\n",
    "            \"forecasting_horizon\": \"72\"\n",
    "         }\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts, # location of the model artifact\n",
    "            destination=\"/opt/ml/processing/model\"), # where to put it in the container\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"].S3Output.S3Uri, # location of the validation data\n",
    "            destination = \"/opt/ml/processing/validation\") # where to put it in the container               \n",
    "                ],\n",
    "    outputs=[ProcessingOutput(source=\"/opt/ml/processing/evaluation\",)],\n",
    "    code=\"code/evaluation.py\",           \n",
    "                )\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name=\"WeatherEval\",\n",
    "    step_args=eval_args,\n",
    "    depends_on=[step_process],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in a step where we take the best model of the 2, retrain it on the full dataset, and then create a forecast\n",
    "# during the eval phase, create a plots directory and save the plots there for manual review\n",
    "# It's nice to visually inspect the plots to see if the model is doing a good job. \n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline already exists, updating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_name = f\"WeatherPipeline-Local-10001\"\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", \n",
    "                                default_value=\"ml.m5.xlarge\"\n",
    "                                )\n",
    "model_approval_status = ParameterString(\n",
    "                                name=\"ModelApprovalStatus\", \n",
    "                                default_value=\"PendingManualApproval\"\n",
    "                                )\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "# update the existing piipline\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,        \n",
    "    ],\n",
    "    steps=[step_process, \n",
    "           step_train,\n",
    "           step_evaluate\n",
    "           ],\n",
    ")\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.list_pipeline_executions(PipelineName=pipeline_name)\n",
    "pipeline_arns = [x['PipelineExecutionArn'] for x in response['PipelineExecutionSummaries']]\n",
    "pipeline_names = [x.split('/')[-3].lower() for x in pipeline_arns]\n",
    "if pipeline_name.lower() in pipeline_names:\n",
    "    print(\"Pipeline already exists, updating\")\n",
    "    pipeline.update(role_arn=role)\n",
    "else:\n",
    "    pipeline.create(role_arn=role)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()\n",
    "steps = execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws sagemaker delete-pipeline --pipeline-name WeatherPipeline-Local-87\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the input and output of the pipeline\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
